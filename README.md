![suhana_right.png](assets/logos/suhana_right.png)

[![Python](https://img.shields.io/badge/Python-3.12%2B-blue?logo=python)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Self-hosted](https://img.shields.io/badge/self--hosted-yes-brightgreen)]()
[![Powered by](https://img.shields.io/badge/LLM-Ollama%20%7C%20OpenAI-9cf)]()

> Suhana _(ìˆ˜í•˜ë‚˜)_ is your self-hosted AI companion: a modular chat agent with a personality, local knowledge base, and the ability to run commands â€” all without giving away your data.

---

## âœ¨ Features

- ðŸ¤– **Chat with a personality** â€“ Suhana remembers you and responds in character
- ðŸ” **Search local knowledge** â€“ markdown, code, and notes in `/knowledge` folder
- ðŸ”„ **Pluggable AI engines** â€“ supports [Ollama](https://ollama.com) (ðŸ¦™) and OpenAI (ðŸ¤–)
- ðŸ§  **Memory-aware** â€“ Suhana evolves with you via `!remember` and `profile.json`
- ðŸ”’ **Self-hosted & portable** â€“ no cloud dependencies, runs on macOS/Windows/Linux
- âš¡ **Execute commands** â€“ define your own actions like `send_message()` or `update_profile()`

---

## ðŸš€ Quick Start

### 1. Clone the project

```bash
git clone https://github.com/Reterics/suhana.git
cd Suhana
```

### 2. Set up Python environment

```bash
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 3. Choose your LLM backend

#### âœ… Option A: [Ollama](https://ollama.com) - local & private

Install Ollama and run one of the supported models:

```bash
ollama run llama3
```
This will download and launch the llama3 model locally.

Other available models include:

- `mistral` â€“ lightweight and fast
- `llama3` â€“ larger and more capable
- `gemma` â€“ Googleâ€™s open model
- `phi` â€“ compact and smart
- `codellama` â€“ optimized for coding tasks
- `llava` â€“ for multimodal (image + text) input

You can set the model in `settings.json`:

```json
{
  "llm_backend": "ollama",
  "llm_model": "llama3"
}
```

#### ðŸ¤– Option B: OpenAI â€“ cloud-powered

 1. Create a .env file in the root of the project with your API key:
    ```dotenv
    OPENAI_API_KEY=sk-...
    ```
 2. In settings.json, set your backend and model:
    ```json
    {
      "llm_backend": "openai",
      "llm_model": "gpt-4"
    }
    ```
> Suhana supports both backends. You can switch at runtime using `!switch openai` or `!switch ollama`.

---

### 4. Ingest your knowledge files

Put `.md`, `.txt`, or `.code` files into `/knowledge`, then run:

```bash
python ingest.py
```

---

### 5. Chat with Suhana

```bash
python main.py
```

Youâ€™ll see:

```
Hello, I'm Suhana ðŸ¦™ â€” powered by: OLLAMA (llama3)
```

---

## ðŸ›  Example Commands

| Command         | Description                             |
|----------------|-----------------------------------------|
| `!engine`       | Show the current model + backend        |
| `!switch openai`| Switch between Ollama and OpenAI        |
| `!remember xyz` | Store user facts in `profile.json`      |
| `!exit`         | Leave the session                       |

---

## ðŸ§© Folder Structure

```
Suhana/
â”œâ”€ engine/         # Core agent logic
â”œâ”€ knowledge/      # Your documents and notes
â”œâ”€ vectorstore/    # Local FAISS index (auto-generated)
â”œâ”€ models/         # Persona config (`persona.yaml`)
â”œâ”€ profile.json    # User memory and preferences
â”œâ”€ settings.json   # Backend + model config
â”œâ”€ ingest.py       # File indexer
â””â”€ main.py         # Entry point
```

---

## ðŸ§  Memory Example

A sample `profile.json`:

```json
{
  "name": "Attila",
  "preferences": {
    "communication_style": "technical, friendly"
  },
  "memory": [
    { "type": "fact", "content": "Attila prefers local models over cloud ones." }
  ]
}
```

---

## ðŸ§  Model Support

| Engine   | Status     | Notes                     |
|----------|------------|---------------------------|
| Ollama   | âœ… Stable   | llama3, mistral, etc.     |
| OpenAI   | âœ… Optional | Requires API key          |
| LocalHF  | ðŸ”œ Planned  | Hugging Face local models |

---

## ðŸ›¡ License

MIT â€” use freely, modify locally, and share improvements.

---
